{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\Student_Performance_Prediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\Student_Performance_Prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    preprocessor_path: Path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from studentPerformance.constants import *\n",
    "from studentPerformance.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            preprocessor_path = config.preprocessor_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.studentPerformance.logger import logging\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,OrdinalEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformer_obj(self):\n",
    "        '''\n",
    "        This function is responsible for data transformation\n",
    "        '''\n",
    "        try:\n",
    "            # Define which columns should be ordinal-encoded and which should be scaled\n",
    "            numerical_columns=['writing_score','reading_score']\n",
    "            categorical_columns=[\n",
    "                'gender',\n",
    "                'race_ethnicity',\n",
    "                'parental_level_of_education',\n",
    "                'lunch',\n",
    "                'test_preparation_course'\n",
    "            ]\n",
    "            \n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            gender = ['female', 'male']\n",
    "            race_ethnicity = ['group B', 'group C', 'group A', 'group D', 'group E']\n",
    "            parental_level_of_education = [\"bachelor's degree\", \"some college\", \"master's degree\", \"associate's degree\",\n",
    "            \"high school\", \"some high school\"]\n",
    "            lunch = ['standard', 'free/reduced']\n",
    "            test_preparation_course = ['none', 'completed']\n",
    "\n",
    "            # Numerical Pipeline\n",
    "            num_pipeline = Pipeline(\n",
    "                steps = [\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())                \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Categorical Pipeline\n",
    "            cat_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinal_encoder',OrdinalEncoder(categories=[gender,\n",
    "                race_ethnicity,\n",
    "                parental_level_of_education,\n",
    "                lunch,\n",
    "                test_preparation_course])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(f'Categorical Columns : {categorical_columns}')\n",
    "            logging.info(f'Numerical Columns   : {numerical_columns}')\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                [\n",
    "                ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                ('cat_pipeline',cat_pipeline,categorical_columns)\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in get_data_transformer_object: {str(e)}\")\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            train_data_path = 'artifacts/data_ingestion/unzipped_data/train_data.csv'\n",
    "            test_data_path = 'artifacts/data_ingestion/unzipped_data/test_data.csv'\n",
    "\n",
    "            logging.info(\"Read train and test data completed\")\n",
    "\n",
    "            logging.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            # Read training and test data\n",
    "            train_df = pd.read_csv(train_data_path)\n",
    "            test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "            logging.info('Read train and test data completed')\n",
    "            logging.info(f'Train Dataframe Head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head  : \\n{test_df.head().to_string()}')\n",
    "\n",
    "            logging.info('Obtaining preprocessing object')\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformer_obj()\n",
    "\n",
    "            target_column_name = 'math_score'\n",
    "\n",
    "            # Separate input features and target features\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "\n",
    "            # Apply the preprocessing object on training and test input features\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            # Combine input features and target features\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            \n",
    "            test_arr = np.c_[\n",
    "                input_feature_test_arr, np.array(target_feature_test_df)\n",
    "            ]\n",
    "\n",
    "            # Save preprocessing object\n",
    "            preprocessing_obj_file = os.path.join(\"artifacts\", 'data_transformation', 'preprocessing_obj.pkl')\n",
    "            with open(preprocessing_obj_file, 'wb') as file:\n",
    "                pickle.dump(preprocessing_obj, file)\n",
    "\n",
    "            logging.info(\"Saved preprocessing object.\")\n",
    "            logging.info(\"Transformation of the data is completed\")\n",
    "            \n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr,\n",
    "                preprocessing_obj_file\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in initiate_data_transformation: {str(e)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-24 02:52:40,253: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-08-24 02:52:40,254: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-08-24 02:52:40,256: INFO: common: created directory at: artifacts]\n",
      "[2023-08-24 02:52:40,269: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2023-08-24 02:52:40,269: INFO: 3862503345: Read train and test data completed]\n",
      "[2023-08-24 02:52:40,270: INFO: 3862503345: Obtaining preprocessing object]\n",
      "[2023-08-24 02:52:40,299: INFO: 3862503345: Read train and test data completed]\n",
      "[2023-08-24 02:52:40,417: INFO: 3862503345: Train Dataframe Head : \n",
      "   gender race_ethnicity parental_level_of_education         lunch test_preparation_course  math_score  reading_score  writing_score\n",
      "0  female        group D             master's degree      standard                    none          62             70             75\n",
      "1  female        group C           bachelor's degree  free/reduced               completed          66             83             83\n",
      "2  female        group D                some college  free/reduced                    none          79             89             86\n",
      "3    male        group C             master's degree  free/reduced                    none          61             67             66\n",
      "4    male        group E                 high school      standard                    none          73             64             57]\n",
      "[2023-08-24 02:52:40,425: INFO: 3862503345: Test Dataframe Head  : \n",
      "   gender race_ethnicity parental_level_of_education         lunch test_preparation_course  math_score  reading_score  writing_score\n",
      "0  female        group C          associate's degree      standard                    none          91             86             84\n",
      "1  female        group B                some college  free/reduced               completed          53             66             73\n",
      "2    male        group D           bachelor's degree      standard                    none          80             73             72\n",
      "3    male        group C                some college  free/reduced                    none          74             77             73\n",
      "4    male        group E                some college      standard               completed          84             83             78]\n",
      "[2023-08-24 02:52:40,427: INFO: 3862503345: Obtaining preprocessing object]\n",
      "[2023-08-24 02:52:40,428: INFO: 3862503345: Categorical Columns : ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']]\n",
      "[2023-08-24 02:52:40,430: INFO: 3862503345: Numerical Columns   : ['writing_score', 'reading_score']]\n",
      "[2023-08-24 02:52:40,527: INFO: 3862503345: Saved preprocessing object.]\n",
      "[2023-08-24 02:52:40,528: INFO: 3862503345: Transformation of the data is completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
