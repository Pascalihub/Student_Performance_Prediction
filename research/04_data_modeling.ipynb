{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PASCAL\\\\Student_Performance_Prediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    model_file_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from studentPerformance.constants import *\n",
    "from studentPerformance.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "        root_dir=config.root_dir,\n",
    "        data_path=config.data_path,\n",
    "        model_path=config.model_path\n",
    "        model_file_path=config.model_file_path\n",
    "    )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from src.studentPerformance.logger import logging\n",
    "from src.studentPerformance.utils.common import evaluate_models\n",
    "from src.studentPerformance.components.data_transformation import DataTransformation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Modelling\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from src.studentPerformance.logger import logging\n",
    "from src.studentPerformance.utils.common import evaluate_models\n",
    "from src.studentPerformance.utils.common import print_evaluated_results\n",
    "from src.studentPerformance.utils.common import model_metrics\n",
    "from src.studentPerformance.utils.common import save_object\n",
    "from src.studentPerformance.components.data_transformation import DataTransformation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def initiate_model_trainer(self, train_array, test_array):\n",
    "        try:\n",
    "            logging.info('Splitting Dependent and Independent variables from train and test data')\n",
    "            xtrain, ytrain, xtest, ytest = (\n",
    "                train_array[:,:-1],\n",
    "                train_array[:,-1],\n",
    "                test_array[:,:-1],\n",
    "                test_array[:,-1]\n",
    "            )\n",
    "            \n",
    "            models = {\n",
    "                \"Linear Regression\": LinearRegression(),\n",
    "                \"Lasso\": Lasso(),\n",
    "                \"Ridge\": Ridge(),\n",
    "                \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "                \"Decision Tree\": DecisionTreeRegressor(),\n",
    "                \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "                \"XGBRegressor\": XGBRegressor(), \n",
    "                \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "                \"GradientBoosting Regressor\":GradientBoostingRegressor(),\n",
    "                \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "            }\n",
    "\n",
    "            model_report:dict = evaluate_models(xtrain,ytrain,xtest,ytest,models)\n",
    "\n",
    "            print(model_report)\n",
    "            print('\\n====================================================================================\\n')\n",
    "            logging.info(f'Model Report : {model_report}')\n",
    "            # To get best model score from dictionary \n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "            best_model = models[best_model_name]\n",
    "\n",
    "            if best_model_score < 0.6 :\n",
    "                logging.info('Best model has r2 Score less than 60%')\n",
    "                raise Exception('No Best Model Found')\n",
    "            \n",
    "            # Save model object\n",
    "            model_file_path = os.path.join(\"artifacts\", \"model_trainer\", \"model.pkl\")\n",
    "            with open(model_file_path, \"wb\") as file:\n",
    "                pickle.dump(best_model, file)\n",
    "\n",
    "            print(f'Best Model Found , Model Name : {best_model_name} , R2 Score : {best_model_score}')\n",
    "            print('\\n====================================================================================\\n')\n",
    "            logging.info(f'Best Model Found , Model Name : {best_model_name} , R2 Score : {best_model_score}')\n",
    "            logging.info('Hyperparameter tuning started for catboost')\n",
    "\n",
    "            # Hyperparameter tuning on Catboost\n",
    "            # Initializing catboost\n",
    "            cbr = CatBoostRegressor(verbose=False)\n",
    "\n",
    "            # Creating the hyperparameter grid\n",
    "            param_dist = {'depth'          : [4,5,6,7,8,9, 10],\n",
    "                          'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "                          'iterations'    : [300,400,500,600]}\n",
    "\n",
    "            #Instantiate RandomSearchCV object\n",
    "            rscv = RandomizedSearchCV(cbr , param_dist, scoring='r2', cv =5, n_jobs=-1)\n",
    "\n",
    "            # Fit the model\n",
    "            rscv.fit(xtrain, ytrain)\n",
    "\n",
    "            # Print the tuned parameters and score\n",
    "            print(f'Best Catboost parameters : {rscv.best_params_}')\n",
    "            print(f'Best Catboost Score : {rscv.best_score_}')\n",
    "            print('\\n====================================================================================\\n')\n",
    "\n",
    "            best_cbr = rscv.best_estimator_\n",
    "\n",
    "            logging.info('Hyperparameter tuning complete for Catboost')\n",
    "\n",
    "            logging.info('Hyperparameter tuning started for KNN')\n",
    "\n",
    "            # Initialize knn\n",
    "            knn = KNeighborsRegressor()\n",
    "\n",
    "            # parameters\n",
    "            k_range = list(range(2, 31))\n",
    "            param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "            # Fitting the cvmodel\n",
    "            grid = GridSearchCV(knn, param_grid, cv=5, scoring='r2',n_jobs=-1)\n",
    "            grid.fit(xtrain, ytrain)\n",
    "\n",
    "            # Print the tuned parameters and score\n",
    "            print(f'Best KNN Parameters : {grid.best_params_}')\n",
    "            print(f'Best KNN Score : {grid.best_score_}')\n",
    "            print('\\n====================================================================================\\n')\n",
    "\n",
    "            best_knn = grid.best_estimator_\n",
    "\n",
    "            logging.info('Hyperparameter tuning Complete for KNN')\n",
    "\n",
    "            logging.info('Voting Regressor model training started')\n",
    "\n",
    "            # Creating final Voting regressor\n",
    "            er = VotingRegressor([('cbr',best_cbr),('xgb',XGBRegressor()),('knn',best_knn)], weights=[3,2,1])\n",
    "            er.fit(xtrain, ytrain)\n",
    "            print('Final Model Evaluation :\\n')\n",
    "            print_evaluated_results(xtrain,ytrain,xtest,ytest,er)\n",
    "            logging.info('Voting Regressor Training Completed')\n",
    "\n",
    "            save_object(\n",
    "                file_path=model_file_path,\n",
    "                obj=er\n",
    "            )\n",
    "\n",
    "            logging.info('Model pickle file saved')\n",
    "            # Evaluating Ensemble Regressor (Voting Classifier on test data)\n",
    "            ytest_pred = er.predict(xtest)\n",
    "\n",
    "            mae, rmse, r2 = model_metrics(ytest, ytest_pred)\n",
    "            logging.info(f'Test MAE : {mae}')\n",
    "            logging.info(f'Test RMSE : {rmse}')\n",
    "            logging.info(f'Test R2 Score : {r2}')\n",
    "            logging.info('Final Model Training Completed')\n",
    "            \n",
    "            return mae, rmse, r2 \n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info('Exception occured at Model Training')\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-24 05:44:20,759: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-08-24 05:44:20,762: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-08-24 05:44:20,764: INFO: common: created directory at: artifacts]\n",
      "[2023-08-24 05:44:20,765: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2023-08-24 05:44:20,766: INFO: data_transformation: Read train and test data completed]\n",
      "[2023-08-24 05:44:20,766: INFO: data_transformation: Obtaining preprocessing object]\n",
      "[2023-08-24 05:44:20,767: INFO: data_transformation: Categorical columns: ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']]\n",
      "[2023-08-24 05:44:20,768: INFO: data_transformation: Numerical columns: ['writing_score', 'reading_score']]\n",
      "[2023-08-24 05:44:20,832: INFO: data_transformation: Saved preprocessing object.]\n",
      "[2023-08-24 05:44:20,833: INFO: data_transformation: Transformation of the data is completed]\n",
      "[2023-08-24 05:44:20,834: INFO: 498946074: Splitting Dependent and Independent variables from train and test data]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear Regression': 0.8795158595242263, 'Lasso': 0.8564278149469471, 'Ridge': 0.8805671790733921, 'K-Neighbors Regressor': 0.47561174068704326, 'Decision Tree': 0.7454573548605563, 'Random Forest Regressor': 0.8529852512962283, 'XGBRegressor': 0.8210206583029993, 'CatBoosting Regressor': 0.8523560006768236, 'GradientBoosting Regressor': 0.8723268951354977, 'AdaBoost Regressor': 0.8438670697740134}\n",
      "\n",
      "====================================================================================\n",
      "\n",
      "[2023-08-24 05:44:23,957: INFO: 498946074: Model Report : {'Linear Regression': 0.8795158595242263, 'Lasso': 0.8564278149469471, 'Ridge': 0.8805671790733921, 'K-Neighbors Regressor': 0.47561174068704326, 'Decision Tree': 0.7454573548605563, 'Random Forest Regressor': 0.8529852512962283, 'XGBRegressor': 0.8210206583029993, 'CatBoosting Regressor': 0.8523560006768236, 'GradientBoosting Regressor': 0.8723268951354977, 'AdaBoost Regressor': 0.8438670697740134}]\n",
      "Best Model Found , Model Name : Ridge , R2 Score : 0.8805671790733921\n",
      "\n",
      "====================================================================================\n",
      "\n",
      "[2023-08-24 05:44:23,959: INFO: 498946074: Best Model Found , Model Name : Ridge , R2 Score : 0.8805671790733921]\n",
      "[2023-08-24 05:44:23,961: INFO: 498946074: Hyperparameter tuning started for catboost]\n",
      "Best Catboost parameters : {'learning_rate': 0.02, 'iterations': 400, 'depth': 4}\n",
      "Best Catboost Score : 0.8586207605050749\n",
      "\n",
      "====================================================================================\n",
      "\n",
      "[2023-08-24 05:44:57,051: INFO: 498946074: Hyperparameter tuning complete for Catboost]\n",
      "[2023-08-24 05:44:57,052: INFO: 498946074: Hyperparameter tuning started for KNN]\n",
      "Best KNN Parameters : {'n_neighbors': 18}\n",
      "Best KNN Score : 0.566815655459106\n",
      "\n",
      "====================================================================================\n",
      "\n",
      "[2023-08-24 05:44:57,757: INFO: 498946074: Hyperparameter tuning Complete for KNN]\n",
      "[2023-08-24 05:44:57,758: INFO: 498946074: Voting Regressor model training started]\n",
      "Final Model Evaluation :\n",
      "\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 3.8831\n",
      "- Mean Absolute Error: 3.1109\n",
      "- R2 Score: 0.9331\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 6.1790\n",
      "- Mean Absolute Error: 4.7021\n",
      "- R2 Score: 0.8431\n",
      "[2023-08-24 05:44:58,658: INFO: 498946074: Voting Regressor Training Completed]\n",
      "[2023-08-24 05:44:58,682: INFO: 498946074: Model pickle file saved]\n",
      "[2023-08-24 05:44:58,704: INFO: 498946074: Test MAE : 4.702088268088517]\n",
      "[2023-08-24 05:44:58,705: INFO: 498946074: Test RMSE : 6.179046916531889]\n",
      "[2023-08-24 05:44:58,707: INFO: 498946074: Test R2 Score : 0.8430966062212036]\n",
      "[2023-08-24 05:44:58,708: INFO: 498946074: Final Model Training Completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    data_transformation = DataTransformation(model_trainer_config)\n",
    "    train_arr, test_arr, _ = data_transformation.initiate_data_transformation()\n",
    "\n",
    "    model_trainer = ModelTrainer(model_trainer_config)\n",
    "    model_trainer.initiate_model_trainer(train_arr, test_arr)\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(self.config.root_dir, \"artifacts/model_trainer\")\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            output_file = os.path.join(output_dir, \"model.pkl\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
